{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iYqwRHTX-mXW"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import keras\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEG_PATH = './CityScapes Dataset/segmentations'\n",
    "IMG_PATH = './CityScapes Dataset/rawimgs'\n",
    "SPLIT = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = DataGenerator(img_path=IMG_PATH, seg_path=SEG_PATH, split='TRAIN',\n",
    "                  n_classes=30,\n",
    "                  input_width=224, input_height=224,\n",
    "                  output_width=112, output_height=112,\n",
    "                  imgNorm='sub_mean',\n",
    "                  ordering='channels_first',\n",
    "                  batch_size=16\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_gen = DataGenerator(img_path=IMG_PATH, seg_path=SEG_PATH, split='TEST',\n",
    "                  n_classes=30,\n",
    "                  input_width=224, input_height=224,\n",
    "                  output_width=112, output_height=112,\n",
    "                  imgNorm='sub_mean',\n",
    "                  ordering='channels_first',\n",
    "                  batch_size=16\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hqs1r1FgWVP9"
   },
   "source": [
    "## Image Segmentation - Preprocess Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cJeriBNBvcML"
   },
   "outputs": [],
   "source": [
    "def VGGUNet(n_classes, weights_path, input_height, input_width, \n",
    "            image_ordering='channels_first'):\n",
    "  \n",
    "    assert input_height % 32 == 0\n",
    "    assert input_width % 32 == 0\n",
    "\n",
    "    img_input = Input(shape=(3, input_height, input_width))\n",
    "\n",
    "    # Block 1\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1', data_format=image_ordering)(\n",
    "        img_input)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2', data_format=image_ordering)(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool', data_format=image_ordering)(x)\n",
    "    f1 = x\n",
    "    \n",
    "    # Block 2\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1', data_format=image_ordering)(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2', data_format=image_ordering)(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool', data_format=image_ordering)(x)\n",
    "    f2 = x\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1', data_format=image_ordering)(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2', data_format=image_ordering)(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3', data_format=image_ordering)(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool', data_format=image_ordering)(x)\n",
    "    f3 = x\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1', data_format=image_ordering)(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2', data_format=image_ordering)(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3', data_format=image_ordering)(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool', data_format=image_ordering)(x)\n",
    "    f4 = x\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1', data_format=image_ordering)(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2', data_format=image_ordering)(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3', data_format=image_ordering)(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool', data_format=image_ordering)(x)\n",
    "    f5 = x\n",
    "\n",
    "    x = Flatten(name='flatten')(x)\n",
    "    x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "    x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "    x = Dense(1000, activation='softmax', name='predictions')(x)\n",
    "\n",
    "    vgg = Model(img_input, x)\n",
    "    vgg.load_weights(weights_path)\n",
    "\n",
    "    o = f4\n",
    "\n",
    "    o = (ZeroPadding2D((1, 1), data_format=image_ordering))(o)\n",
    "    o = (Conv2D(512, (3, 3), padding='valid', data_format=image_ordering))(o)\n",
    "    o = (BatchNormalization())(o)\n",
    "\n",
    "    o = (UpSampling2D((2, 2), data_format=image_ordering))(o)\n",
    "    o = (concatenate([o, f3], axis=1))\n",
    "    o = (ZeroPadding2D((1, 1), data_format=image_ordering))(o)\n",
    "    o = (Conv2D(256, (3, 3), padding='valid', data_format=image_ordering))(o)\n",
    "    o = (BatchNormalization())(o)\n",
    "\n",
    "    o = (UpSampling2D((2, 2), data_format=image_ordering))(o)\n",
    "    o = (concatenate([o, f2], axis=1))\n",
    "    o = (ZeroPadding2D((1, 1), data_format=image_ordering))(o)\n",
    "    o = (Conv2D(128, (3, 3), padding='valid', data_format=image_ordering))(o)\n",
    "    o = (BatchNormalization())(o)\n",
    "\n",
    "    o = (UpSampling2D((2, 2), data_format=image_ordering))(o)\n",
    "    o = (concatenate([o, f1], axis=1))\n",
    "    o = (ZeroPadding2D((1, 1), data_format=image_ordering))(o)\n",
    "    o = (Conv2D(64, (3, 3), padding='valid', data_format=image_ordering))(o)\n",
    "    o = (BatchNormalization())(o)\n",
    "\n",
    "    o = Conv2D(n_classes, (3, 3), padding='same', data_format=image_ordering)(o)\n",
    "    o_shape = Model(img_input, o).output_shape\n",
    "    outputHeight = o_shape[2]\n",
    "    outputWidth = o_shape[3]\n",
    "\n",
    "    o = (Reshape((n_classes, outputHeight * outputWidth)))(o)\n",
    "    o = (Permute((2, 1)))(o)\n",
    "    o = (Activation('softmax'))(o)\n",
    "    model = Model(img_input, o)\n",
    "    model.outputWidth = outputWidth\n",
    "    model.outputHeight = outputHeight\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "IMAGE_ORDERING = 'channels_first'\n",
    "VGG_WEIGHTS_PATH = \"vgg16_weights_th_dim_ordering_th_kernels.h5\"\n",
    "N_CLASSES = 30\n",
    "INPUT_HEIGHT = 224\n",
    "INPUT_WIDTH = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run VGG UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGGUNet(N_CLASSES, VGG_WEIGHTS_PATH, INPUT_HEIGHT, INPUT_WIDTH, IMAGE_ORDERING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           (None, 3, 224, 224)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 64, 224, 224) 1792        input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 64, 224, 224) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 64, 112, 112) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 128, 112, 112 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 128, 112, 112 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 128, 56, 56)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 256, 56, 56)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 256, 56, 56)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 256, 56, 56)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 256, 28, 28)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 512, 28, 28)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 512, 28, 28)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 512, 28, 28)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 512, 14, 14)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_37 (ZeroPadding2 (None, 512, 16, 16)  0           block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 512, 14, 14)  2359808     zero_padding2d_37[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 512, 14, 14)  56          conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_28 (UpSampling2D) (None, 512, 28, 28)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 768, 28, 28)  0           up_sampling2d_28[0][0]           \n",
      "                                                                 block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_38 (ZeroPadding2 (None, 768, 30, 30)  0           concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 256, 28, 28)  1769728     zero_padding2d_38[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 256, 28, 28)  112         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_29 (UpSampling2D) (None, 256, 56, 56)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 384, 56, 56)  0           up_sampling2d_29[0][0]           \n",
      "                                                                 block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_39 (ZeroPadding2 (None, 384, 58, 58)  0           concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 128, 56, 56)  442496      zero_padding2d_39[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 128, 56, 56)  224         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_30 (UpSampling2D) (None, 128, 112, 112 0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 192, 112, 112 0           up_sampling2d_30[0][0]           \n",
      "                                                                 block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_40 (ZeroPadding2 (None, 192, 114, 114 0           concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 64, 112, 112) 110656      zero_padding2d_40[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 64, 112, 112) 448         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 30, 112, 112) 17310       batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 30, 12544)    0           conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "permute_4 (Permute)             (None, 12544, 30)    0           reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 12544, 30)    0           permute_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 12,336,102\n",
      "Trainable params: 12,335,682\n",
      "Non-trainable params: 420\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = 'adam',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 54/100 [===============>..............] - ETA: 40:19 - loss: 0.4907 - acc: 0.4350"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-4:\n",
      "Process ForkPoolWorker-3:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-cf61e1d212d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit_generator(generator=train_gen, steps_per_epoch=100, \n\u001b[1;32m      2\u001b[0m                 \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                 epochs=5, use_multiprocessing=True)\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'vgg_unet_weights'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/image-segmentation-keras/.iseg/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/image-segmentation-keras/.iseg/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/image-segmentation-keras/.iseg/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/image-segmentation-keras/.iseg/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/image-segmentation-keras/.iseg/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/image-segmentation-keras/.iseg/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/image-segmentation-keras/.iseg/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit_generator(generator=train_gen, steps_per_epoch=100, \n",
    "                validation_data=val_gen, validation_steps=200, \n",
    "                epochs=5, use_multiprocessing=True)\n",
    "\n",
    "m.save_weights('vgg_unet_weights')\n",
    "\n",
    "m.save('vgg_unet' + \".model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lj_9Bt39iIpZ"
   },
   "outputs": [],
   "source": [
    "base_dir = \".\"\n",
    "X_train_path = os.path.join(base_dir, \"images_prepped_train/\")\n",
    "y_train_path = os.path.join(base_dir, \"annotations_prepped_train/\")\n",
    "X_val_path = os.path.join(base_dir, \"images_prepped_test/\")\n",
    "y_val_path = os.path.join(base_dir, \"annotations_prepped_test/\")\n",
    "\n",
    "\n",
    "batch_size = 2\n",
    "epochs = 5\n",
    "n_classes = 10\n",
    "input_height = 224\n",
    "input_width = 224\n",
    "output_height = 112\n",
    "output_width = 112"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_segmentation_dataset(X_path, y_path, n_classes, \n",
    "                               input_height, input_width, \n",
    "                               output_height, output_width):\n",
    "  \n",
    "    assert X_path[-1] == '/'\n",
    "    assert y_path[-1] == '/'\n",
    "\n",
    "    images = glob.glob(X_path + \"*.jpg\") + glob.glob(X_path + \"*.png\") + glob.glob(X_path + \"*.jpeg\")\n",
    "    images.sort()\n",
    "    segmentations = glob.glob(y_path + \"*.jpg\") + glob.glob(y_path + \"*.png\") + glob.glob(y_path + \"*.jpeg\")\n",
    "    segmentations.sort()\n",
    "\n",
    "    assert len(images) == len(segmentations)\n",
    "    \n",
    "    for im, seg in zip(images, segmentations):\n",
    "        assert (im.split('/')[-1].split(\".\")[0] == seg.split('/')[-1].split(\".\")[0])\n",
    "        \n",
    "    print(\"Making datasets!\")\n",
    "    X = [getImageArr(im, input_width, input_height) for im in images]\n",
    "    y = [getSegmentationArr(seg, n_classes, output_width, output_height) for seg in segmentations]\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "y9co4l0IiAF1",
    "outputId": "feef37de-53f8-4b11-a782-74c06d25ad6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making datasets!\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = image_segmentation_dataset(\n",
    "    X_train_path, y_train_path, n_classes, \n",
    "    input_height, input_width, \n",
    "    output_height, output_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rzUMo-swiNuO",
    "outputId": "34930a0a-d38b-4997-8d80-a48125032dab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making datasets!\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = image_segmentation_dataset(\n",
    "    X_val_path, y_val_path, n_classes, \n",
    "    input_height, input_width, \n",
    "    output_height, output_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qBMthQ0SqMib",
    "outputId": "7b8ea04e-9265-4006-979a-6b4dbdc7a5d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(367, 3, 224, 224)"
      ]
     },
     "execution_count": 59,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Mqwqina2qSnS",
    "outputId": "eb7f9a3b-a94a-48ca-e098-ae8d667d9a82"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(367, 12544, 10)"
      ]
     },
     "execution_count": 60,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YV4kkDuLyVog",
    "outputId": "56a90092-1eac-46d6-a44e-a2704bebb1cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, 3, 224, 224)"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vX-X9VIjyVh4",
    "outputId": "bdf432d1-22a4-4e50-a0ea-c30ea8be5d99"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, 12544, 10)"
      ]
     },
     "execution_count": 67,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HsbDDMQj63JU"
   },
   "source": [
    "## Create VGG U-Net Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fie6ldvLMnv0"
   },
   "outputs": [],
   "source": [
    "model = VGGUNet(n_classes, \n",
    "                VGG_weights_path, \n",
    "                input_height, \n",
    "                input_width)\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = 'adam',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0OoyguDR4gaU"
   },
   "source": [
    "## Active Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_HN1Pyfh1avv"
   },
   "outputs": [],
   "source": [
    "def train_test_split(X, y, percent):\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    X_test = list(X)\n",
    "    y_test = list(y)\n",
    "    \n",
    "    train_size = int(len(X_test) * percent)\n",
    "    \n",
    "    while len(X_train) < train_size:\n",
    "      index = randrange(len(X_test))\n",
    "      X_train.append(X_test.pop(index))\n",
    "      y_train.append(y_test.pop(index))\n",
    "      \n",
    "    return np.array(X_test), np.array(y_test), np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RA37J4du-yGn"
   },
   "outputs": [],
   "source": [
    "def split_dataset(X_train, X_test, y_train, y_test, initial_annotated_perc=0.1):  \n",
    "    X_pool, y_pool, X_initial, y_initial = train_test_split(X_train, \n",
    "                                                            y_train, \n",
    "                                                            initial_annotated_perc)\n",
    "    return X_pool, y_pool, X_initial, y_initial, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Iz1ObcGg-yD8"
   },
   "outputs": [],
   "source": [
    "def initialize_model(model, X_initial, y_initial, X_test, y_test, \n",
    "                     n_classes, epochs, batch_size, verbose):\n",
    "    \n",
    "    model.fit(X_initial, y_initial, validation_data=(X_test, y_test), \n",
    "              shuffle=True, batch_size=2, epochs=epochs, verbose=verbose)\n",
    "\n",
    "    scores = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=verbose)\n",
    "    print('Initial Test Loss: ', scores[0], ' Initial Test Accuracy: ', scores[1])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xzi5peef-v1O"
   },
   "outputs": [],
   "source": [
    "# Random sampling\n",
    "def random_sampling(y_pred_prob, n_samples):\n",
    "    return np.random.choice(range(len(y_pred_prob)), n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D1AVynA3-vyg"
   },
   "outputs": [],
   "source": [
    "# Rank all the unlabeled samples in an ascending order according to the least confidence\n",
    "def least_confidence(y_pred_prob, n_samples):\n",
    "    origin_index = np.arange(0, len(y_pred_prob))\n",
    "    max_prob = np.max(y_pred_prob, axis=1)\n",
    "    pred_label = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "    lci = np.column_stack((origin_index,\n",
    "                           max_prob,\n",
    "                           pred_label))\n",
    "    lci = lci[lci[:, 1].argsort()]\n",
    "    return lci[:n_samples], lci[:, 0].astype(int)[:n_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "peoVsOeq-vvN"
   },
   "outputs": [],
   "source": [
    "# Rank all the unlabeled samples in an ascending order according to the margin sampling\n",
    "def margin_sampling(y_pred_prob, n_samples):\n",
    "    origin_index = np.arange(0, len(y_pred_prob))\n",
    "    margim_sampling = np.diff(-np.sort(y_pred_prob)[:, ::-1][:, :2])\n",
    "    pred_label = np.argmax(y_pred_prob, axis=1)\n",
    "    msi = np.column_stack((origin_index,\n",
    "                           margim_sampling,\n",
    "                           pred_label))\n",
    "    msi = msi[msi[:, 1].argsort()]\n",
    "    return msi[:n_samples], msi[:, 0].astype(int)[:n_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vw6BOUDM-scz"
   },
   "outputs": [],
   "source": [
    "# Rank all the unlabeled samples in an descending order according to their entropy\n",
    "def entropy(y_pred_prob, n_samples):\n",
    "    origin_index = np.arange(0, len(y_pred_prob))\n",
    "    entropy = -np.nansum(np.multiply(y_pred_prob, np.log(y_pred_prob)), axis=1)\n",
    "    pred_label = np.argmax(y_pred_prob, axis=1)\n",
    "    eni = np.column_stack((origin_index,\n",
    "                           entropy,\n",
    "                           pred_label))\n",
    "\n",
    "    eni = eni[(-eni[:, 1]).argsort()]\n",
    "    return eni[:n_samples], eni[:, 0].astype(int)[:n_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sQ1AXYDD-sZ8"
   },
   "outputs": [],
   "source": [
    "def get_high_confidence_samples(y_pred_prob, delta):\n",
    "    eni, eni_idx = entropy(y_pred_prob, len(y_pred_prob))\n",
    "    hcs = eni[eni[:, 1] < delta]\n",
    "    return hcs[:, 0].astype(int), hcs[:, 2].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3joHw0fL-pEc"
   },
   "outputs": [],
   "source": [
    "def get_uncertain_samples(y_pred_prob, n_samples, criteria):\n",
    "    if criteria == 'lc':\n",
    "        return least_confidence(y_pred_prob, n_samples)\n",
    "    elif criteria == 'ms':\n",
    "        return margin_sampling(y_pred_prob, n_samples)\n",
    "    elif criteria == 'en':\n",
    "        return entropy(y_pred_prob, n_samples)\n",
    "    elif criteria == 'rs':\n",
    "        return None, random_sampling(y_pred_prob, n_samples)\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            'Unknown criteria value \\'%s\\', use one of [\\'rs\\',\\'lc\\',\\'ms\\',\\'en\\']' % criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SU8cy6ft-pBT"
   },
   "outputs": [],
   "source": [
    "def run_ceal(X_train, X_test, y_train, y_test,\n",
    "             model, maximum_iterations, cost_effective, verbose, \n",
    "             uncertain_samples_size, uncertain_criteria, \n",
    "             delta, threshold_decay, fine_tuning_interval,\n",
    "             epochs, batch_size, earlystop):\n",
    "    \n",
    "    X_pool, y_pool, X_initial, y_initial, X_test, y_test = split_dataset(X_train, X_test, y_train, y_test, 0.1)    \n",
    "    \n",
    "    print('X_pool.shape:', X_pool.shape)\n",
    "    print('y_pool.shape:', y_pool.shape)\n",
    "    print('X_initial.shape:', X_initial.shape)\n",
    "    print('y_initial.shape:', y_initial.shape)\n",
    "    print('X_test.shape:', X_test.shape)\n",
    "    print('y_test.shape:', y_test.shape)\n",
    "    \n",
    "    model = initialize_model(model, X_initial, y_initial, X_test, y_test, \n",
    "                             n_classes, epochs, batch_size, verbose)\n",
    "\n",
    "    w, h, c = X_pool[-1,].shape\n",
    "\n",
    "    # unlabeled samples\n",
    "    DU = X_pool, y_pool\n",
    "\n",
    "    # initially labeled samples\n",
    "    DL = X_initial, y_initial\n",
    "\n",
    "    # high confidence samples\n",
    "    DH = np.empty((0, w, h, c)), np.empty((0, n_classes))\n",
    "\n",
    "    for i in range(maximum_iterations):\n",
    "\n",
    "        y_pred_prob = model.predict(DU[0], verbose=verbose)\n",
    "\n",
    "        _, un_idx = get_uncertain_samples(y_pred_prob, uncertain_samples_size, criteria=uncertain_criteria)\n",
    "        DL = np.append(DL[0], np.take(DU[0], un_idx, axis=0), axis=0), \\\n",
    "             np.append(DL[1], np.take(DU[1], un_idx, axis=0), axis=0)\n",
    "\n",
    "        if cost_effective:\n",
    "            hc_idx, hc_labels = get_high_confidence_samples(y_pred_prob, delta)\n",
    "            # remove samples also selected through uncertain\n",
    "            hc = np.array([[i, l] for i, l in zip(hc_idx, hc_labels) if i not in un_idx])\n",
    "            if hc.size != 0:\n",
    "                DH = np.take(DU[0], hc[:, 0], axis=0), np_utils.to_categorical(hc[:, 1], n_classes)\n",
    "\n",
    "        if i % fine_tuning_interval == 0:\n",
    "            dtrain_x = np.concatenate((DL[0], DH[0])) if DH[0].size != 0 else DL[0]\n",
    "            dtrain_y = np.concatenate((DL[1], DH[1])) if DH[1].size != 0 else DL[1]\n",
    "\n",
    "            model.fit(dtrain_x, dtrain_y, validation_data=(X_test, y_test), batch_size=batch_size,\n",
    "                      shuffle=True, epochs=epochs, verbose=verbose, callbacks=[earlystop])\n",
    "            delta -= (threshold_decay * fine_tuning_interval)\n",
    "\n",
    "        DU = np.delete(DU[0], un_idx, axis=0), np.delete(DU[1], un_idx, axis=0)\n",
    "        DH = np.empty((0, w, h, c)), np.empty((0, n_classes))\n",
    "\n",
    "        _, acc = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=verbose)\n",
    "        \n",
    "        print(\n",
    "            'Iteration: %d; High Confidence Samples: %d; Uncertain Samples: %d; Delta: %.5f; Labeled Dataset Size: %d; Accuracy: %.2f'\n",
    "            % (i, len(DH[0]), len(DL[0]), delta, len(DL[0]), acc))\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "7TwtclRCBtUS",
    "outputId": "b7c34f8e-e769-4760-a049-84bddf9a9b99"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-180-03a19dbcaa29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m                  \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                  \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                  earlystop=earlystop)\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: run_ceal() got an unexpected keyword argument 'earlystop'"
     ]
    }
   ],
   "source": [
    "# keras callbacks\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=1)\n",
    "\n",
    "model = run_ceal(X_train=X_train, \n",
    "                 X_test=X_test, \n",
    "                 y_train=y_train, \n",
    "                 y_test=y_test,\n",
    "                 model=model,\n",
    "                 maximum_iterations=10, \n",
    "                 cost_effective=True, \n",
    "                 verbose=1, \n",
    "                 uncertain_samples_size=10,\n",
    "                 uncertain_criteria='lc', \n",
    "                 delta=0.05, \n",
    "                 threshold_decay=0.0033, \n",
    "                 fine_tuning_interval=1,\n",
    "                 epochs=5,\n",
    "                 batch_size=2, \n",
    "                 earlystop=earlystop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 229
    },
    "colab_type": "code",
    "id": "ZnnHECqVJCwq",
    "outputId": "6b2e6510-6c97-4d9a-f84e-e3d11b141928"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-179-61708bde083b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mConverge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "class Converge(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        return\n",
    " \n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    " \n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    " \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "      if logs['acc'] > 0.80:\n",
    "          self.model.stop_training = True\n",
    "          print(f\"Stopping after {epoch+1} epochs.\")\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    " \n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "czXnp9Oq_Jo3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fGgcToCVBJ2r"
   },
   "source": [
    "## VGG U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "f5ijqJ3D14Gh",
    "outputId": "4bb1b100-e2ae-445d-cd32-7a9e0b37d143"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output shape (None, 12544, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Model output shape\" , m.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cP8qUCoS3N_e"
   },
   "outputs": [],
   "source": [
    "G = imageSegmentationGenerator(X_train_path, y_train_path, batch_size, n_classes, input_height, input_width, m.outputHeight, m.outputWidth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "egN75_ssYS_j"
   },
   "outputs": [],
   "source": [
    "G_val = imageSegmentationGenerator(X_val_path, y_val_path, batch_size, n_classes, input_height, input_width, m.outputHeight, m.outputWidth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "C3bH1jeApgxN",
    "outputId": "e3a4ef29-a4de-457e-92e6-4bd7c3393523"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object imageSegmentationGenerator at 0x7f07f05d2a40>"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rQhr0aA5YS8k"
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "m.fit_generator(generator=G, steps_per_epoch=512, \n",
    "                validation_data=G_val, validation_steps=200, \n",
    "                epochs=15, use_multiprocessing=True)\n",
    "\n",
    "m.save_weights(base_dir + 'vggnet_weights')\n",
    "m.save(base_dir + 'vggnet_weights' + \".vggunet_model\")\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print('VGG U-Net training time:', elapsed_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mnD_oQtYDaaK"
   },
   "source": [
    "## FCN32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yt4M8J_C3eyj"
   },
   "outputs": [],
   "source": [
    "def FCN32(n_classes, weights_path, input_height, input_width, image_ordering='channels_first'):\n",
    "  \n",
    "    assert input_height % 32 == 0\n",
    "    assert input_width % 32 == 0\n",
    "\n",
    "    img_input = Input(shape=(3, input_height, input_width))\n",
    "\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1', data_format=image_ordering)(\n",
    "        img_input)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2', data_format=image_ordering)(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool', data_format=image_ordering)(x)\n",
    "    f1 = x\n",
    "    \n",
    "    # Block 2\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1', data_format=image_ordering)(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2', data_format=image_ordering)(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool', data_format=image_ordering)(x)\n",
    "    f2 = x\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1', data_format=image_ordering)(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2', data_format=image_ordering)(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3', data_format=image_ordering)(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool', data_format=image_ordering)(x)\n",
    "    f3 = x\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1', data_format=image_ordering)(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2', data_format=image_ordering)(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3', data_format=image_ordering)(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool', data_format=image_ordering)(x)\n",
    "    f4 = x\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1', data_format=image_ordering)(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2', data_format=image_ordering)(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3', data_format=image_ordering)(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool', data_format=image_ordering)(x)\n",
    "    f5 = x\n",
    "\n",
    "    x = Flatten(name='flatten')(x)\n",
    "    x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "    x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "    x = Dense(1000, activation='softmax', name='predictions')(x)\n",
    "\n",
    "    vgg = Model(img_input, x)\n",
    "    vgg.load_weights(weights_path)\n",
    "\n",
    "    o = f5\n",
    "\n",
    "    o = (Conv2D(4096, (7, 7), activation='relu', padding='same', data_format=image_ordering))(o)\n",
    "    o = Dropout(0.5)(o)\n",
    "    o = (Conv2D(4096, (1, 1), activation='relu', padding='same', data_format=image_ordering))(o)\n",
    "    o = Dropout(0.5)(o)\n",
    "\n",
    "    o = (Conv2D(n_classes, (1, 1), kernel_initializer='he_normal', data_format=image_ordering))(o)\n",
    "    o = Conv2DTranspose(n_classes, kernel_size=(64, 64), \n",
    "                        strides=(32, 32), use_bias=False, \n",
    "                        data_format=image_ordering)(o)\n",
    "    o_shape = Model(img_input, o).output_shape\n",
    "\n",
    "    outputHeight = o_shape[2]\n",
    "    outputWidth = o_shape[3]\n",
    "\n",
    "    print(\"koko\", o_shape)\n",
    "\n",
    "    o = (Reshape((-1, outputHeight * outputWidth)))(o)\n",
    "    o = (Permute((2, 1)))(o)\n",
    "    o = (Activation('softmax'))(o)\n",
    "    model = Model(img_input, o)\n",
    "    model.outputWidth = outputWidth\n",
    "    model.outputHeight = outputHeight\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_6QbzC2Y3ewk",
    "outputId": "11156fc7-e08f-4167-a2a9-0dfbb279d876"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "koko (None, 10, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "m = FCN32(10, \n",
    "          VGG_weights_path, \n",
    "          input_height, \n",
    "          input_width)\n",
    "\n",
    "m.compile(loss = 'categorical_crossentropy',\n",
    "          optimizer = 'adam',\n",
    "          metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bB9y621BSJlg"
   },
   "outputs": [],
   "source": [
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "colab_type": "code",
    "id": "X00RqZZVSQ4m",
    "outputId": "1a4ad525-c703-4f53-a1bc-18d1e82092b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "100/100 [==============================] - 27s 273ms/step - loss: 0.9268 - acc: 0.6208 - val_loss: 1.1054 - val_acc: 0.5850\n",
      "Epoch 2/15\n",
      "100/100 [==============================] - 27s 272ms/step - loss: 0.7578 - acc: 0.7165 - val_loss: 1.9422 - val_acc: 0.3922\n",
      "Epoch 3/15\n",
      "100/100 [==============================] - 27s 273ms/step - loss: 0.8793 - acc: 0.6593 - val_loss: 1.3506 - val_acc: 0.4661\n",
      "Epoch 4/15\n",
      "100/100 [==============================] - 27s 273ms/step - loss: 0.7235 - acc: 0.7293 - val_loss: 1.1284 - val_acc: 0.5539\n",
      "Epoch 5/15\n",
      "100/100 [==============================] - 27s 272ms/step - loss: 0.8706 - acc: 0.6615 - val_loss: 1.9203 - val_acc: 0.3664\n",
      "Epoch 6/15\n",
      "100/100 [==============================] - 27s 271ms/step - loss: 0.7564 - acc: 0.7021 - val_loss: 1.2095 - val_acc: 0.5487\n",
      "Epoch 7/15\n",
      "100/100 [==============================] - 27s 272ms/step - loss: 0.8000 - acc: 0.7031 - val_loss: 1.0328 - val_acc: 0.6319\n",
      "Epoch 8/15\n",
      "100/100 [==============================] - 27s 272ms/step - loss: 0.8194 - acc: 0.6664 - val_loss: 1.4145 - val_acc: 0.5401\n",
      "Epoch 9/15\n",
      "100/100 [==============================] - 27s 270ms/step - loss: 0.7207 - acc: 0.7322 - val_loss: 1.2525 - val_acc: 0.5646\n",
      "Epoch 10/15\n",
      "100/100 [==============================] - 27s 271ms/step - loss: 0.8873 - acc: 0.6322 - val_loss: 1.6836 - val_acc: 0.4802\n",
      "Epoch 11/15\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 0.6807 - acc: 0.7594 - val_loss: 0.8762 - val_acc: 0.6635\n",
      "Epoch 12/15\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 0.8880 - acc: 0.6324 - val_loss: 0.9655 - val_acc: 0.6381\n",
      "Epoch 13/15\n",
      "100/100 [==============================] - 27s 273ms/step - loss: 0.7240 - acc: 0.7280 - val_loss: 1.2380 - val_acc: 0.5349\n",
      "Epoch 14/15\n",
      "100/100 [==============================] - 27s 272ms/step - loss: 0.8614 - acc: 0.6547 - val_loss: 0.9482 - val_acc: 0.6308\n",
      "Epoch 15/15\n",
      "100/100 [==============================] - 27s 271ms/step - loss: 0.6968 - acc: 0.7342 - val_loss: 0.9432 - val_acc: 0.6423\n"
     ]
    }
   ],
   "source": [
    "m.fit_generator(generator=G, steps_per_epoch=100, \n",
    "                validation_data=G_val, validation_steps=200, \n",
    "                epochs=15, use_multiprocessing=True)\n",
    "\n",
    "m.save_weights(base_dir + 'vggnet_weights')\n",
    "m.save(base_dir + 'vggnet_weights' + \".fcn32_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JnXWTmJ-aBOL"
   },
   "source": [
    "## FCN8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YYD9SEy1a3-n"
   },
   "outputs": [],
   "source": [
    "# Crop o1 with respect to o2\n",
    "def crop(o1, o2, i, image_ordering='channels_first'):\n",
    "    o_shape2 = Model(i, o2).output_shape\n",
    "    outputHeight2 = o_shape2[2]\n",
    "    outputWidth2 = o_shape2[3]\n",
    "\n",
    "    o_shape1 = Model(i, o1).output_shape\n",
    "    outputHeight1 = o_shape1[2]\n",
    "    outputWidth1 = o_shape1[3]\n",
    "\n",
    "    cx = abs(outputWidth1 - outputWidth2)\n",
    "    cy = abs(outputHeight2 - outputHeight1)\n",
    "\n",
    "    if outputWidth1 > outputWidth2:\n",
    "        o1 = Cropping2D(cropping=((0, 0), (0, cx)), data_format=image_ordering)(o1)\n",
    "    else:\n",
    "        o2 = Cropping2D(cropping=((0, 0), (0, cx)), data_format=image_ordering)(o2)\n",
    "\n",
    "    if outputHeight1 > outputHeight2:\n",
    "        o1 = Cropping2D(cropping=((0, cy), (0, 0)), data_format=image_ordering)(o1)\n",
    "    else:\n",
    "        o2 = Cropping2D(cropping=((0, cy), (0, 0)), data_format=image_ordering)(o2)\n",
    "\n",
    "    return o1, o2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SCKHy1poSNYE"
   },
   "outputs": [],
   "source": [
    "def FCN8(nClasses, weights_path, input_height, input_width, image_ordering='channels_first'):\n",
    "\n",
    "    img_input = Input(shape=(3, input_height, input_width))\n",
    "\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1', data_format=image_ordering)(\n",
    "        img_input)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2', data_format=image_ordering)(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool', data_format=image_ordering)(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1', data_format=image_ordering)(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2', data_format=image_ordering)(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool', data_format=image_ordering)(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1', data_format=image_ordering)(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2', data_format=image_ordering)(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3', data_format=image_ordering)(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool', data_format=image_ordering)(x)\n",
    "    f3 = x\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1', data_format=image_ordering)(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2', data_format=image_ordering)(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3', data_format=image_ordering)(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool', data_format=image_ordering)(x)\n",
    "    f4 = x\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1', data_format=image_ordering)(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2', data_format=image_ordering)(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3', data_format=image_ordering)(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool', data_format=image_ordering)(x)\n",
    "    f5 = x\n",
    "\n",
    "    x = Flatten(name='flatten')(x)\n",
    "    x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "    x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "    x = Dense(1000, activation='softmax', name='predictions')(x)\n",
    "\n",
    "    vgg = Model(img_input, x)\n",
    "    vgg.load_weights(weights_path)\n",
    "\n",
    "    o = f5\n",
    "    o = (Conv2D(4096, (7, 7), activation='relu', padding='same', data_format=image_ordering))(o)\n",
    "    o = Dropout(0.5)(o)\n",
    "    o = (Conv2D(4096, (1, 1), activation='relu', padding='same', data_format=image_ordering))(o)\n",
    "    o = Dropout(0.5)(o)\n",
    "    o = (Conv2D(nClasses, (1, 1), kernel_initializer='he_normal', data_format=image_ordering))(o)\n",
    "    o = Conv2DTranspose(nClasses, kernel_size=(4, 4), strides=(2, 2), use_bias=False, data_format=image_ordering)(o)\n",
    "    o2 = f4\n",
    "    o2 = (Conv2D(nClasses, (1, 1), kernel_initializer='he_normal', data_format=image_ordering))(o2)\n",
    "\n",
    "    o, o2 = crop(o, o2, img_input, image_ordering)\n",
    "    o = Add()([o, o2])\n",
    "    o = Conv2DTranspose(nClasses, kernel_size=(4, 4), strides=(2, 2), use_bias=False, data_format=image_ordering)(o)\n",
    "    o2 = f3\n",
    "    o2 = (Conv2D(nClasses, (1, 1), kernel_initializer='he_normal', data_format=image_ordering))(o2)\n",
    "    \n",
    "    o2, o = crop(o2, o, img_input, image_ordering)\n",
    "    o = Add()([o2, o])\n",
    "\n",
    "    o = Conv2DTranspose(nClasses, kernel_size=(16, 16), strides=(8, 8), use_bias=False, data_format=image_ordering)(o)\n",
    "\n",
    "    o_shape = Model(img_input, o).output_shape\n",
    "\n",
    "    outputHeight = o_shape[2]\n",
    "    outputWidth = o_shape[3]\n",
    "\n",
    "    o = (Reshape((-1, outputHeight * outputWidth)))(o)\n",
    "    o = (Permute((2, 1)))(o)\n",
    "    o = (Activation('softmax'))(o)\n",
    "    model = Model(img_input, o)\n",
    "    model.outputWidth = outputWidth\n",
    "    model.outputHeight = outputHeight\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7lPVFUmESNVe"
   },
   "outputs": [],
   "source": [
    "m = FCN8(10, \n",
    "         VGG_weights_path, \n",
    "         input_height, \n",
    "         input_width)\n",
    "\n",
    "m.compile(loss = 'categorical_crossentropy',\n",
    "          optimizer = 'adam',\n",
    "          metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 538
    },
    "colab_type": "code",
    "id": "9TxNL51UbEzc",
    "outputId": "332d16a8-b3ab-41cc-996b-f88771aff045"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "100/100 [==============================] - 95s 947ms/step - loss: 10.4528 - acc: 0.3152 - val_loss: 10.4180 - val_acc: 0.3189\n",
      "Epoch 2/15\n",
      "100/100 [==============================] - 86s 857ms/step - loss: 9.7570 - acc: 0.3553 - val_loss: 10.7778 - val_acc: 0.2997\n",
      "Epoch 3/15\n",
      "100/100 [==============================] - 86s 856ms/step - loss: 11.1892 - acc: 0.2745 - val_loss: 12.3560 - val_acc: 0.1987\n",
      "Epoch 4/15\n",
      "100/100 [==============================] - 86s 857ms/step - loss: 12.1863 - acc: 0.1991 - val_loss: 12.3605 - val_acc: 0.1987\n",
      "Epoch 5/15\n",
      "100/100 [==============================] - 86s 857ms/step - loss: 12.1931 - acc: 0.2192 - val_loss: 12.3599 - val_acc: 0.1987\n",
      "Epoch 6/15\n",
      "100/100 [==============================] - 86s 857ms/step - loss: 12.1332 - acc: 0.1979 - val_loss: 12.3584 - val_acc: 0.1987\n",
      "Epoch 7/15\n",
      "100/100 [==============================] - 86s 857ms/step - loss: 12.2762 - acc: 0.2185 - val_loss: 12.3577 - val_acc: 0.1987\n",
      "Epoch 8/15\n",
      "100/100 [==============================] - 86s 856ms/step - loss: 12.0273 - acc: 0.2040 - val_loss: 12.2011 - val_acc: 0.2083\n",
      "Epoch 9/15\n",
      "100/100 [==============================] - 86s 857ms/step - loss: 12.0209 - acc: 0.2245 - val_loss: 12.1996 - val_acc: 0.2083\n",
      "Epoch 10/15\n",
      "100/100 [==============================] - 86s 857ms/step - loss: 12.0550 - acc: 0.2077 - val_loss: 12.1983 - val_acc: 0.2084\n",
      "Epoch 11/15\n",
      "100/100 [==============================] - 86s 856ms/step - loss: 11.9855 - acc: 0.2239 - val_loss: 12.1972 - val_acc: 0.2084\n",
      "Epoch 12/15\n",
      "100/100 [==============================] - 86s 857ms/step - loss: 12.1470 - acc: 0.2070 - val_loss: 12.1965 - val_acc: 0.2084\n",
      "Epoch 13/15\n",
      "100/100 [==============================] - 86s 857ms/step - loss: 12.0264 - acc: 0.2137 - val_loss: 12.1954 - val_acc: 0.2085\n",
      "Epoch 14/15\n",
      "100/100 [==============================] - 86s 856ms/step - loss: 12.1133 - acc: 0.2161 - val_loss: 12.1953 - val_acc: 0.2086\n",
      "Epoch 15/15\n",
      "100/100 [==============================] - 86s 857ms/step - loss: 11.9433 - acc: 0.2141 - val_loss: 11.9091 - val_acc: 0.2260\n",
      "FCN8 training time: 1313.578024148941\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "m.fit_generator(generator=G, steps_per_epoch=100, \n",
    "                validation_data=G_val, validation_steps=200, \n",
    "                epochs=15, use_multiprocessing=True)\n",
    "\n",
    "m.save_weights(base_dir + 'vggnet_weights')\n",
    "m.save(base_dir + 'vggnet_weights' + \".fcn8_model\")\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print('FCN8 training time:', elapsed_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w9dHKH_OMV7m"
   },
   "source": [
    "## VGG SegNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BFf5EtpG3es_"
   },
   "outputs": [],
   "source": [
    "def VGGSegNet(n_classes, weights_path, input_height, input_width, vgg_level=3):\n",
    "    img_input = Input(shape=(3, input_height, input_width))\n",
    "\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1', data_format='channels_first')(\n",
    "        img_input)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2', data_format='channels_first')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool', data_format='channels_first')(x)\n",
    "    f1 = x\n",
    "    \n",
    "    # Block 2\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1', data_format='channels_first')(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2', data_format='channels_first')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool', data_format='channels_first')(x)\n",
    "    f2 = x\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1', data_format='channels_first')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2', data_format='channels_first')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3', data_format='channels_first')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool', data_format='channels_first')(x)\n",
    "    f3 = x\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1', data_format='channels_first')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2', data_format='channels_first')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3', data_format='channels_first')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool', data_format='channels_first')(x)\n",
    "    f4 = x\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1', data_format='channels_first')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2', data_format='channels_first')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3', data_format='channels_first')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool', data_format='channels_first')(x)\n",
    "    f5 = x\n",
    "\n",
    "    x = Flatten(name='flatten')(x)\n",
    "    x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "    x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "    x = Dense(1000, activation='softmax', name='predictions')(x)\n",
    "\n",
    "    vgg = Model(img_input, x)\n",
    "    vgg.load_weights(weights_path)\n",
    "\n",
    "    levels = [f1, f2, f3, f4, f5]\n",
    "\n",
    "    o = levels[vgg_level]\n",
    "\n",
    "    o = (ZeroPadding2D((1, 1), data_format='channels_first'))(o)\n",
    "    o = (Conv2D(512, (3, 3), padding='valid', data_format='channels_first'))(o)\n",
    "    o = (BatchNormalization())(o)\n",
    "\n",
    "    o = (UpSampling2D((2, 2), data_format='channels_first'))(o)\n",
    "    o = (ZeroPadding2D((1, 1), data_format='channels_first'))(o)\n",
    "    o = (Conv2D(256, (3, 3), padding='valid', data_format='channels_first'))(o)\n",
    "    o = (BatchNormalization())(o)\n",
    "\n",
    "    o = (UpSampling2D((2, 2), data_format='channels_first'))(o)\n",
    "    o = (ZeroPadding2D((1, 1), data_format='channels_first'))(o)\n",
    "    o = (Conv2D(128, (3, 3), padding='valid', data_format='channels_first'))(o)\n",
    "    o = (BatchNormalization())(o)\n",
    "\n",
    "    o = (UpSampling2D((2, 2), data_format='channels_first'))(o)\n",
    "    o = (ZeroPadding2D((1, 1), data_format='channels_first'))(o)\n",
    "    o = (Conv2D(64, (3, 3), padding='valid', data_format='channels_first'))(o)\n",
    "    o = (BatchNormalization())(o)\n",
    "\n",
    "    o = Conv2D(n_classes, (3, 3), padding='same', data_format='channels_first')(o)\n",
    "    o_shape = Model(img_input, o).output_shape\n",
    "    outputHeight = o_shape[2]\n",
    "    outputWidth = o_shape[3]\n",
    "\n",
    "    o = (Reshape((-1, outputHeight * outputWidth)))(o)\n",
    "    o = (Permute((2, 1)))(o)\n",
    "    o = (Activation('softmax'))(o)\n",
    "    model = Model(img_input, o)\n",
    "    model.outputWidth = outputWidth\n",
    "    model.outputHeight = outputHeight\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aqx4FkWLYS5Y"
   },
   "outputs": [],
   "source": [
    "m = VGGSegNet(10, \n",
    "              VGG_weights_path, \n",
    "              input_height, \n",
    "              input_width)\n",
    "\n",
    "m.compile(loss = 'categorical_crossentropy',\n",
    "          optimizer = 'adam',\n",
    "          metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1277
    },
    "colab_type": "code",
    "id": "KHJy26szWHUj",
    "outputId": "49da8f91-361a-407f-add5-6d758d8f7f5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 3, 224, 224)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 64, 224, 224)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 64, 224, 224)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 112, 112)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 128, 112, 112)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 128, 112, 112)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 128, 56, 56)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 256, 56, 56)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 256, 56, 56)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 256, 56, 56)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 256, 28, 28)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 512, 28, 28)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 512, 28, 28)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 512, 28, 28)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 512, 14, 14)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_9 (ZeroPaddin (None, 512, 16, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 512, 14, 14)       2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 512, 14, 14)       56        \n",
      "_________________________________________________________________\n",
      "up_sampling2d_7 (UpSampling2 (None, 512, 28, 28)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_10 (ZeroPaddi (None, 512, 30, 30)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 256, 28, 28)       1179904   \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 256, 28, 28)       112       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_8 (UpSampling2 (None, 256, 56, 56)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_11 (ZeroPaddi (None, 256, 58, 58)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 128, 56, 56)       295040    \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 128, 56, 56)       224       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_9 (UpSampling2 (None, 128, 112, 112)     0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_12 (ZeroPaddi (None, 128, 114, 114)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 64, 112, 112)      73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 64, 112, 112)      448       \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 10, 112, 112)      5770      \n",
      "_________________________________________________________________\n",
      "reshape_4 (Reshape)          (None, 10, 12544)         0         \n",
      "_________________________________________________________________\n",
      "permute_4 (Permute)          (None, 12544, 10)         0         \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 12544, 10)         0         \n",
      "=================================================================\n",
      "Total params: 11,550,418\n",
      "Trainable params: 11,549,998\n",
      "Non-trainable params: 420\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1458
    },
    "colab_type": "code",
    "id": "-cEKwElUWJTo",
    "outputId": "bfd60f2f-2746-40fd-e0cf-a0908d831884"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "100/100 [==============================] - 27s 272ms/step - loss: 0.8889 - acc: 0.6288 - val_loss: 1.0426 - val_acc: 0.6414\n",
      "Epoch 2/15\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 0.7134 - acc: 0.7310 - val_loss: 2.5854 - val_acc: 0.3728\n",
      "Epoch 3/15\n",
      "100/100 [==============================] - 27s 271ms/step - loss: 0.8679 - acc: 0.6508 - val_loss: 0.8867 - val_acc: 0.6663\n",
      "Epoch 4/15\n",
      "100/100 [==============================] - 27s 270ms/step - loss: 0.6987 - acc: 0.7354 - val_loss: 0.9369 - val_acc: 0.6285\n",
      "Epoch 5/15\n",
      "100/100 [==============================] - 27s 270ms/step - loss: 0.8566 - acc: 0.6582 - val_loss: 0.9442 - val_acc: 0.6352\n",
      "Epoch 6/15\n",
      "100/100 [==============================] - 27s 272ms/step - loss: 0.7363 - acc: 0.7112 - val_loss: 1.1906 - val_acc: 0.5189\n",
      "Epoch 7/15\n",
      "100/100 [==============================] - 27s 270ms/step - loss: 0.7734 - acc: 0.7029 - val_loss: 1.2015 - val_acc: 0.6056\n",
      "Epoch 8/15\n",
      "100/100 [==============================] - 27s 271ms/step - loss: 0.8027 - acc: 0.6701 - val_loss: 1.0930 - val_acc: 0.5485\n",
      "Epoch 9/15\n",
      "100/100 [==============================] - 27s 271ms/step - loss: 0.6807 - acc: 0.7449 - val_loss: 0.9774 - val_acc: 0.6674\n",
      "Epoch 10/15\n",
      "100/100 [==============================] - 27s 271ms/step - loss: 0.8642 - acc: 0.6355 - val_loss: 1.2800 - val_acc: 0.5387\n",
      "Epoch 11/15\n",
      "100/100 [==============================] - 27s 273ms/step - loss: 0.6415 - acc: 0.7744 - val_loss: 1.0262 - val_acc: 0.6180\n",
      "Epoch 12/15\n",
      "100/100 [==============================] - 27s 273ms/step - loss: 0.8609 - acc: 0.6383 - val_loss: 0.9329 - val_acc: 0.6637\n",
      "Epoch 13/15\n",
      "100/100 [==============================] - 27s 271ms/step - loss: 0.6777 - acc: 0.7473 - val_loss: 1.6325 - val_acc: 0.4224\n",
      "Epoch 14/15\n",
      "100/100 [==============================] - 27s 271ms/step - loss: 0.8288 - acc: 0.6660 - val_loss: 0.8073 - val_acc: 0.6694\n",
      "Epoch 15/15\n",
      "100/100 [==============================] - 27s 272ms/step - loss: 0.6554 - acc: 0.7489 - val_loss: 1.0028 - val_acc: 0.6350\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-87071720590b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m m.fit_generator(generator=G, steps_per_epoch=100, \n\u001b[1;32m      2\u001b[0m                 \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mG_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                 epochs=15, use_multiprocessing=True)\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'vggnet_weights'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mval_enqueuer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                 \u001b[0mval_enqueuer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mstop\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munfinished_tasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m         \u001b[0m_SHARED_SEQUENCES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "m.fit_generator(generator=G, steps_per_epoch=100, \n",
    "                validation_data=G_val, validation_steps=200, \n",
    "                epochs=15, use_multiprocessing=True)\n",
    "\n",
    "m.save_weights(base_dir + 'vggnet_weights')\n",
    "m.save(base_dir + 'vggnet_weights' + \".vgg_segnet_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "colab_type": "code",
    "id": "acLCRmHtMRTf",
    "outputId": "84cc40c4-2be3-4792-b956-502721bdc18d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "512/512 [==============================] - 91s 177ms/step - loss: 0.7503 - acc: 0.7020 - val_loss: 1.1700 - val_acc: 0.6248\n",
      "Epoch 2/15\n",
      "512/512 [==============================] - 90s 177ms/step - loss: 0.7153 - acc: 0.7153 - val_loss: 0.8926 - val_acc: 0.6558\n",
      "Epoch 3/15\n",
      "512/512 [==============================] - 90s 176ms/step - loss: 0.6796 - acc: 0.7423 - val_loss: 1.6742 - val_acc: 0.4541\n",
      "Epoch 4/15\n",
      "512/512 [==============================] - 90s 176ms/step - loss: 0.6369 - acc: 0.7663 - val_loss: 0.8517 - val_acc: 0.7180\n",
      "Epoch 5/15\n",
      "512/512 [==============================] - 90s 176ms/step - loss: 0.5921 - acc: 0.7923 - val_loss: 0.7160 - val_acc: 0.7604\n",
      "Epoch 6/15\n",
      "512/512 [==============================] - 89s 175ms/step - loss: 0.5581 - acc: 0.8029 - val_loss: 0.7444 - val_acc: 0.7396\n",
      "Epoch 7/15\n",
      "512/512 [==============================] - 90s 175ms/step - loss: 0.5186 - acc: 0.8141 - val_loss: 0.7548 - val_acc: 0.7440\n",
      "Epoch 8/15\n",
      "512/512 [==============================] - 90s 175ms/step - loss: 0.4867 - acc: 0.8260 - val_loss: 0.6901 - val_acc: 0.7743\n",
      "Epoch 9/15\n",
      "512/512 [==============================] - 90s 176ms/step - loss: 0.4600 - acc: 0.8343 - val_loss: 0.6212 - val_acc: 0.7893\n",
      "Epoch 10/15\n",
      "512/512 [==============================] - 90s 175ms/step - loss: 0.4423 - acc: 0.8414 - val_loss: 0.5619 - val_acc: 0.7973\n",
      "Epoch 11/15\n",
      "512/512 [==============================] - 89s 174ms/step - loss: 0.4392 - acc: 0.8396 - val_loss: 0.6535 - val_acc: 0.7795\n",
      "Epoch 12/15\n",
      "512/512 [==============================] - 89s 175ms/step - loss: 0.4117 - acc: 0.8472 - val_loss: 0.6778 - val_acc: 0.7774\n",
      "Epoch 13/15\n",
      "512/512 [==============================] - 90s 175ms/step - loss: 0.4053 - acc: 0.8501 - val_loss: 0.7727 - val_acc: 0.7610\n",
      "Epoch 14/15\n",
      "512/512 [==============================] - 90s 175ms/step - loss: 0.3839 - acc: 0.8576 - val_loss: 0.6977 - val_acc: 0.7579\n",
      "Epoch 15/15\n",
      "512/512 [==============================] - 90s 175ms/step - loss: 0.3743 - acc: 0.8604 - val_loss: 0.5903 - val_acc: 0.8013\n"
     ]
    }
   ],
   "source": [
    "m.fit_generator(generator=G, steps_per_epoch=512, \n",
    "                validation_data=G_val, validation_steps=200, \n",
    "                epochs=15, use_multiprocessing=True)\n",
    "\n",
    "m.save_weights(base_dir + 'vggnet_weights')\n",
    "m.save(base_dir + 'vggnet_weights' + \".vgg_segnet_model\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "active_learning_image_segmentation.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "segmentation",
   "language": "python",
   "name": "segmentation"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
